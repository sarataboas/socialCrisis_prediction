{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9730e839",
   "metadata": {},
   "source": [
    "## **Model Performance Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8745ac85",
   "metadata": {},
   "source": [
    "**Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6277b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(file_path): \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7317c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_metrics(results_dict, positive_label=\"1\"):\n",
    "    cm = results_dict[\"confusion_matrix\"]\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "\n",
    "    # Recall for each class\n",
    "    recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    recall_neg = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "    gmean = np.sqrt(recall_pos * recall_neg)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": results_dict[\"accuracy\"],\n",
    "        \"Balanced Accuracy\": results_dict[\"balanced_accuracy\"],\n",
    "        \"Precision (Crisis)\": results_dict[\"classification_report\"][positive_label][\"precision\"],\n",
    "        \"Recall (Crisis)\": recall_pos,\n",
    "        \"F1-score (Crisis)\": results_dict[\"classification_report\"][positive_label][\"f1-score\"],\n",
    "        \"G-Mean\": gmean\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8582f",
   "metadata": {},
   "source": [
    "### **Models trained with Baseline Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82027e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = read_json('../outputs/results_base.json')\n",
    "results_oversampling = read_json('../outputs/results_oversampling.json')\n",
    "results_focal_loss = read_json('../outputs/results_focal_loss.json')\n",
    "results_class_weights = read_json('../outputs/results_class_weights.json')\n",
    "results_cost_sensitive = read_json('../outputs/results_cost_sensitive.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0e5ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision (Crisis)</th>\n",
       "      <th>Recall (Crisis)</th>\n",
       "      <th>F1-score (Crisis)</th>\n",
       "      <th>G-Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline LSTM</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Window Oversampling</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focal Loss</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class Weights</th>\n",
       "      <td>0.762</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaptive Cost-Sensitive</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Balanced Accuracy  Precision (Crisis)  \\\n",
       "Baseline LSTM               0.200              0.565               0.091   \n",
       "Window Oversampling         0.640              0.804               0.182   \n",
       "Focal Loss                  0.440              0.696               0.125   \n",
       "Class Weights               0.762              0.875               0.167   \n",
       "Adaptive Cost-Sensitive     0.714              0.850               0.143   \n",
       "\n",
       "                         Recall (Crisis)  F1-score (Crisis)  G-Mean  \n",
       "Baseline LSTM                        1.0              0.167   0.361  \n",
       "Window Oversampling                  1.0              0.308   0.780  \n",
       "Focal Loss                           1.0              0.222   0.626  \n",
       "Class Weights                        1.0              0.286   0.866  \n",
       "Adaptive Cost-Sensitive              1.0              0.250   0.837  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Baseline LSTM\": extract_metrics(results_base),\n",
    "        \"Window Oversampling\": extract_metrics(results_oversampling),\n",
    "        \"Focal Loss\": extract_metrics(results_focal_loss),\n",
    "        \"Class Weights\": extract_metrics(results_class_weights),\n",
    "        \"Adaptive Cost-Sensitive\": extract_metrics(results_cost_sensitive),\n",
    "    },\n",
    "    orient=\"index\"\n",
    ")\n",
    "\n",
    "\n",
    "results_table = results_table.round(3)\n",
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c273d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Performance comparison of imbalance-handling techniques}\n",
      "\\label{tab:imbalance_results}\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & Accuracy & Balanced Accuracy & Precision (Crisis) & Recall (Crisis) & F1-score (Crisis) & G-Mean \\\\\n",
      "\\midrule\n",
      "Baseline LSTM & 0.200 & 0.565 & 0.091 & 1.000 & 0.167 & 0.361 \\\\\n",
      "Window Oversampling & 0.640 & 0.804 & 0.182 & 1.000 & 0.308 & 0.780 \\\\\n",
      "Focal Loss & 0.520 & 0.739 & 0.143 & 1.000 & 0.250 & 0.692 \\\\\n",
      "Class Weights & 0.762 & 0.875 & 0.167 & 1.000 & 0.286 & 0.866 \\\\\n",
      "Adaptive Cost-Sensitive & 0.714 & 0.850 & 0.143 & 1.000 & 0.250 & 0.837 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    results_table.to_latex(\n",
    "        float_format=\"%.3f\",\n",
    "        caption=\"Performance comparison of imbalance-handling techniques\",\n",
    "        label=\"tab:imbalance_results\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccb005",
   "metadata": {},
   "source": [
    "### **Models trained with Imputed Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "534dcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = read_json('../outputs/results_base_imputed.json')\n",
    "results_oversampling = read_json('../outputs/results_oversampling_imputed.json')\n",
    "results_focal_loss = read_json('../outputs/results_focal_loss_imputed.json')\n",
    "results_class_weights = read_json('../outputs/results_class_weights_imputed.json')\n",
    "results_cost_sensitive = read_json('../outputs/results_cost_sensitive_imputed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18fe88c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision (Crisis)</th>\n",
       "      <th>Recall (Crisis)</th>\n",
       "      <th>F1-score (Crisis)</th>\n",
       "      <th>G-Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Imputed LSTM</th>\n",
       "      <td>0.465</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Window Oversampling Imputed</th>\n",
       "      <td>0.628</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focal Loss Imputed</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class Weights Imputed</th>\n",
       "      <td>0.744</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaptive Cost-Sensitive Imputed</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy  Balanced Accuracy  \\\n",
       "Baseline Imputed LSTM               0.465              0.720   \n",
       "Window Oversampling Imputed         0.628              0.805   \n",
       "Focal Loss Imputed                  0.744              0.866   \n",
       "Class Weights Imputed               0.744              0.865   \n",
       "Adaptive Cost-Sensitive Imputed     0.795              0.655   \n",
       "\n",
       "                                 Precision (Crisis)  Recall (Crisis)  \\\n",
       "Baseline Imputed LSTM                         0.080              1.0   \n",
       "Window Oversampling Imputed                   0.111              1.0   \n",
       "Focal Loss Imputed                            0.154              1.0   \n",
       "Class Weights Imputed                         0.167              1.0   \n",
       "Adaptive Cost-Sensitive Imputed               0.125              0.5   \n",
       "\n",
       "                                 F1-score (Crisis)  G-Mean  \n",
       "Baseline Imputed LSTM                        0.148   0.663  \n",
       "Window Oversampling Imputed                  0.200   0.781  \n",
       "Focal Loss Imputed                           0.267   0.855  \n",
       "Class Weights Imputed                        0.286   0.854  \n",
       "Adaptive Cost-Sensitive Imputed              0.200   0.637  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table_imputed = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Baseline Imputed LSTM\": extract_metrics(results_base),\n",
    "        \"Window Oversampling Imputed\": extract_metrics(results_oversampling),\n",
    "        \"Focal Loss Imputed\": extract_metrics(results_focal_loss),\n",
    "        \"Class Weights Imputed\": extract_metrics(results_class_weights),\n",
    "        \"Adaptive Cost-Sensitive Imputed\": extract_metrics(results_cost_sensitive),\n",
    "    },\n",
    "    orient=\"index\"\n",
    ")\n",
    "\n",
    "results_table_imputed = results_table_imputed.round(3)\n",
    "results_table_imputed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
